#  CWDset: A Remote Sensing Dataset for Semantic Segmentation of Small-Scale Coal Waste Dumps

This is the official code repository for the *Scientific Data* paper: **[A dataset of small-scale coal waste dumps in Shanxi Province, China from high-resolution satellite images]**.

## Key Features

* **Dataset:** 4-channel (R, G, B, NIR) high-resolution remote sensing imagery.
* **Custom Code:** Includes robust data loaders (`LoadTiffImageFromFile`,`LoadTiffAnnotations`) and augmentation pipelines (`RandomCropTiff`, `RandomFlipTiff`,`RandomResizeTiff`) **specifically designed for 4-channel TIF data**.
* **Benchmarks:** "Plug-and-play" configurations for 7 major segmentation models (BiSeNetV2, DeepLabV3+, Mask2Former, OCRNet, PSPNet, SegFormer, UNet).
* **Environment:** A 100% locked, reproducible, and stable Conda + PyTorch environment.

---

## ğŸ”§ 1. Installation
### Step 1: Clone This Repository
### æ­¥éª¤ 1ï¼šå…‹éš†æœ¬é¡¹ç›®
```bash
# [Please insert your GitHub repository clone link here]
# [è¯·åœ¨æ­¤å¤„æ’å…¥ä½ çš„ GitHub ä»“åº“å…‹éš†é“¾æ¥]
git clone [https://github.com/ä½ çš„ç”¨æˆ·å/pythonProject.git](https://github.com/ä½ çš„ç”¨æˆ·å/pythonProject.git)
cd pythonProject
```
### Step 2: Create the Conda Environment
```bash
# 1. Create a clean Python 3.10 environment
conda create -n mmlab_stable python=3.10 -y

# 2. Activate the new environment
conda activate mmlab_stable
```
### Step 3ï¼šInstall PyTorch and mmcv-full
```bash
# 1. Install PyTorch 2.1.2 (LTS) + CUDA 12.1 Toolkit
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121

# 2. Install "mmcv-full" (v2.1.0)
pip install "mmcv==2.1.0" -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.1/index.html
```
### Step 4:Install All Remaining Dependencies
```bash
pip install -r requirements.txt
```
## 2. Data Preparation

1ã€The CWDset dataset is permanently archived on Zenodo: CWDset æ•°æ®é›† (v1.0) å·²è¢«æ°¸ä¹…å½’æ¡£åœ¨ Zenodoï¼š [Your Zenodo DOI Link Here, e.g., https://doi.org/10.5281/zenodo.XXXXXXX] [åœ¨æ­¤å¤„æ’å…¥ä½ çš„ Zenodo DOI é“¾æ¥, ä¾‹å¦‚: https://doi.org/10.5281/zenodo.XXXXXXX]

2ã€Download the dataset.

3ã€Unzip the file and ensure your final project structure looks like this: 
```bash
pythonProject/
â”œâ”€â”€ configs/
â”œâ”€â”€ CWDset_code/
â”œâ”€â”€ tools/
â”œâ”€â”€ work_dirs/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ CWDset/
â”‚       â”œâ”€â”€ images/
â”‚       â”‚   â”œâ”€â”€ train/
â”‚       â”‚   â”‚   â”œâ”€â”€ img1.tif
â”‚       â”‚   â”‚   â””â”€â”€ ...
â”‚       â”‚   â””â”€â”€ val/
â”‚       â”‚       â””â”€â”€ ...
â”‚       â””â”€â”€ labels/
â”‚           â”œâ”€â”€ train/
â”‚           â”‚   â”œâ”€â”€ img1.tif
â”‚           â”‚   â””â”€â”€ ...
â”‚           â””â”€â”€ val/
â”‚               â””â”€â”€ ...
â””â”€â”€ README.md
```
## 3.How to Reproduce
train  Models 
All 7 models are configured to train for 110,000 iterations and will only save the single best checkpoint based on val/mIoU.
All models were trained in the mmlab_stable environment on a single NVIDIA RTX 4080 SUPER for 110,000 iterations.

Example: Train BiSeNetV2: ä¾‹å¦‚ï¼Œè®­ç»ƒ BiSeNetV2:
```bash
python tools/train.py configs/bisenetv2_fcn_b4_110k_CWDset-512x512.py
```
Testing (Evaluate mIoU) 
You can evaluate mIoU using either the weights you trained yourself, or our provided pre-trained weights.

Pre-trained Weights Location / é¢„è®­ç»ƒæƒé‡åœ°å€: We provide the final benchmark weights for all 7 models, permanently archived at: æˆ‘ä»¬æä¾›äº†æ‰€æœ‰ 7 ä¸ªæ¨¡å‹çš„æœ€ç»ˆåŸºå‡†æƒé‡ï¼Œå®ƒä»¬è¢«æ°¸ä¹…å½’æ¡£åœ¨ï¼š

[LINK TO YOUR PRE-TRAINED WEIGHTS ON ZENODO OR GITHUB RELEASES] [è¯·åœ¨æ­¤å¤„æ’å…¥ä½ çš„é¢„è®­ç»ƒæƒé‡åœ¨ Zenodo æˆ– GitHub Releases ä¸Šçš„é“¾æ¥]

Please download these weights (e.g., into a new pre-trained/ folder). 

Example: Test BiSeNetV2 using our pre-trained weight: ç¤ºä¾‹ï¼šä½¿ç”¨æˆ‘ä»¬æä¾›çš„é¢„è®­ç»ƒæƒé‡æµ‹è¯• BiSeNetV2ï¼š
```bash
# Usage: python tools/test.py [CONFIG_FILE] [CHECKPOINT_FILE]
# æ ¼å¼: python tools/test.py [é…ç½®æ–‡ä»¶] [æƒé‡æ–‡ä»¶]
python tools/test.py configs/bisenetv2_fcn_b4_110k_CWDset-512x512.py pre-trained/bisenetv2_best_miou.pth
```
Example: Test your self-trained BiSeNetV2 model: ç¤ºä¾‹ï¼šæµ‹è¯•ä½ è‡ªè®­ç»ƒçš„ BiSeNetV2 æ¨¡å‹ï¼š
```bash
python tools/test.py configs/bisenetv2_fcn_b4_110k_CWDset-512x512.py work_dirs/bisenetv2_fcn_b4_110k_CWDset-512x512/best_val_mIoU_iter_XXXX.pth
```


